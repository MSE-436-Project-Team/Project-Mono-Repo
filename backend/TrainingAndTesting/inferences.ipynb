{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Statistics Prediction - Inference\n",
    "\n",
    "This notebook loads all trained models and makes predictions on the latest season features data for the 2025-26 season.\n",
    "\n",
    "## Models Used:\n",
    "1. **Ridge Regression** (Linear model with regularization)\n",
    "2. **XGBoost** (Gradient boosting)\n",
    "3. **LightGBM** (Gradient boosting)\n",
    "4. **Bayesian Multi-Output Regression** (PyMC with MatrixNormal)\n",
    "5. **LSTM** (Deep learning with PyTorch)\n",
    "6. **Transformer** (Deep learning with PyTorch)\n",
    "7. **Ensemble Methods** (Simple averaging, Weighted averaging, Stacking)\n",
    "\n",
    "## Input Data:\n",
    "- `latest_season_features_for_inference.csv`: Features for the 2024-25 season\n",
    "\n",
    "## Output:\n",
    "- Individual model predictions saved as CSV files in Output folder with player mapping\n",
    "- Ensemble predictions saved as CSV files in Output folder with player mapping\n",
    "- Comprehensive comparison and analysis\n",
    "- Predictions for 2025-26 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend directory: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend\n",
      "CSV directory: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/CSVs\n",
      "Models directory: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Models\n",
      "Output directory: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output\n"
     ]
    }
   ],
   "source": [
    "def find_backend_dir(start_path=None):\n",
    "    \"\"\"\n",
    "    Walk up directories from start_path (or cwd) until a folder named 'backend' is found.\n",
    "    Returns the absolute path to the 'backend' folder.\n",
    "    \"\"\"\n",
    "    if start_path is None:\n",
    "        start_path = os.getcwd()\n",
    "    curr_path = os.path.abspath(start_path)\n",
    "    while True:\n",
    "        # Check if 'backend' exists in this directory\n",
    "        candidate = os.path.join(curr_path, \"backend\")\n",
    "        if os.path.isdir(candidate):\n",
    "            return candidate\n",
    "        # If at filesystem root, stop\n",
    "        parent = os.path.dirname(curr_path)\n",
    "        if curr_path == parent:\n",
    "            break\n",
    "        curr_path = parent\n",
    "    raise FileNotFoundError(f\"No 'backend' directory found upward from {start_path}\")\n",
    "\n",
    "# Find the backend directory and CSV folder\n",
    "backend_dir = find_backend_dir()\n",
    "csv_dir = os.path.join(backend_dir, \"CSVs\")\n",
    "models_dir = os.path.join(backend_dir, \"Models\")\n",
    "output_dir = os.path.join(backend_dir, \"Output\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Backend directory: {backend_dir}\")\n",
    "print(f\"CSV directory: {csv_dir}\")\n",
    "print(f\"Models directory: {models_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading inference data...\n",
      "Inference data shape: (422, 58)\n",
      "Columns: 58\n",
      "\n",
      "First few columns: ['PERSON_ID', 'SEASON_ID', 'Points', 'Minutes', 'FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%']\n",
      "\n",
      "Sample data:\n",
      "   PERSON_ID SEASON_ID     Points    Minutes        FGM        FGA        FG%  \\\n",
      "0     2544.0   2023-24  25.661972  35.323944   9.647887  17.873239  54.223944   \n",
      "1   101108.0   2023-24   9.189655  26.431034   3.551724   8.051724  42.506897   \n",
      "2   200768.0   2023-24   8.116667  28.183333   2.716667   6.283333  40.971667   \n",
      "3   201142.0   2023-24  27.093333  37.200000  10.013333  19.146667  53.098667   \n",
      "4   201143.0   2023-24   8.646154  26.800000   3.292308   6.446154  51.089231   \n",
      "\n",
      "        3PM       3PA        3P%  ...  SEASON_Spring        AGE  \\\n",
      "0  2.098592  5.112676  40.459155  ...           True  40.514716   \n",
      "1  1.344828  3.620690  33.778947  ...           True  40.167009   \n",
      "2  1.633333  4.166667  38.740678  ...           True  39.282683   \n",
      "3  2.240000  5.426667  42.233333  ...           True  36.766598   \n",
      "4  1.661538  3.969231  41.303175  ...           True  39.091034   \n",
      "\n",
      "   EXPERIENCE_YEARS  HEIGHT_INCHES  WEIGHT        BMI  DRAFT_POSITION  \\\n",
      "0                22             81   250.0  26.789705            31.0   \n",
      "1                20             72   175.0  23.734004            34.0   \n",
      "2                19             72   196.0  26.582084            54.0   \n",
      "3                18             83   240.0  24.493622            32.0   \n",
      "4                18             81   240.0  25.718116            33.0   \n",
      "\n",
      "   TOP_10_PICK  LOTTERY_PICK  POSITION_CATEGORY  \n",
      "0            0             0                  3  \n",
      "1            0             0                  1  \n",
      "2            0             0                  1  \n",
      "3            0             0                  3  \n",
      "4            0             0                  3  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the inference data\n",
    "print(\"Loading inference data...\")\n",
    "inference_data = pd.read_csv(os.path.join(csv_dir, \"latest_season_features_for_inference.csv\"))\n",
    "\n",
    "print(f\"Inference data shape: {inference_data.shape}\")\n",
    "print(f\"Columns: {len(inference_data.columns)}\")\n",
    "print(f\"\\nFirst few columns: {list(inference_data.columns[:10])}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(inference_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading column information...\n",
      "Loaded column info from ridge_columns.joblib\n",
      "\n",
      "Feature columns: 56\n",
      "Target columns: 21\n",
      "\n",
      "Target variables: ['next_Points', 'next_FTM', 'next_FTA', 'next_FGM', 'next_FGA', 'next_TO', 'next_STL', 'next_BLK', 'next_PF', 'next_USAGE_RATE', 'next_OREB', 'next_DREB', 'next_AST', 'next_REB', 'next_Minutes', 'next_3PM', 'next_3PA', 'next_3P%', 'next_FT%', 'next_FG%', 'next_GAME_EFFICIENCY']\n"
     ]
    }
   ],
   "source": [
    "# Load column information from different model files\n",
    "print(\"Loading column information...\")\n",
    "\n",
    "# Try to load column info from different model files\n",
    "column_info_sources = [\n",
    "    'ridge_columns.joblib',\n",
    "    'tree_models_columns.joblib',\n",
    "    'bayesian_multioutput_columns.joblib',\n",
    "    'lstm_columns.joblib',\n",
    "    'transformer_columns.joblib'\n",
    "]\n",
    "\n",
    "feature_cols = None\n",
    "target_cols = None\n",
    "\n",
    "for source in column_info_sources:\n",
    "    try:\n",
    "        columns_info = joblib.load(os.path.join(models_dir, source))\n",
    "        feature_cols = columns_info['feature_cols']\n",
    "        target_cols = columns_info['target_cols']\n",
    "        print(f\"Loaded column info from {source}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load from {source}: {e}\")\n",
    "        continue\n",
    "\n",
    "if feature_cols is None or target_cols is None:\n",
    "    # Fallback: infer columns from inference data\n",
    "    feature_cols = [col for col in inference_data.columns if not col.startswith('next_') and col not in ['PERSON_ID', 'SEASON_ID']]\n",
    "    target_cols = [col for col in inference_data.columns if col.startswith('next_')]\n",
    "    print(\"Using fallback column inference\")\n",
    "\n",
    "print(f\"\\nFeature columns: {len(feature_cols)}\")\n",
    "print(f\"Target columns: {len(target_cols)}\")\n",
    "print(f\"\\nTarget variables: {target_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing inference data...\n",
      "Inference features shape: (422, 56)\n",
      "Missing values: 108\n",
      "Final inference features shape: (422, 56)\n"
     ]
    }
   ],
   "source": [
    "# Prepare inference data\n",
    "print(\"Preparing inference data...\")\n",
    "\n",
    "# Select features\n",
    "X_inference = inference_data[feature_cols].copy()\n",
    "\n",
    "# Handle infinite values\n",
    "X_inference.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"Inference features shape: {X_inference.shape}\")\n",
    "print(f\"Missing values: {X_inference.isnull().sum().sum()}\")\n",
    "\n",
    "# Check if we have the required columns\n",
    "missing_cols = set(feature_cols) - set(X_inference.columns)\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "    # Add missing columns with zeros\n",
    "    for col in missing_cols:\n",
    "        X_inference[col] = 0\n",
    "\n",
    "# Ensure correct column order\n",
    "X_inference = X_inference[feature_cols]\n",
    "\n",
    "print(f\"Final inference features shape: {X_inference.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Run Individual Models\n",
    "\n",
    "We'll load each trained model and make predictions using their respective prediction functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load model predictions using direct model loading\n",
    "def load_model_predictions(model_name, X_inference, models_dir):\n",
    "    \"\"\"\n",
    "    Load pre-trained model and get predictions by loading models directly\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model_name == 'ridge':\n",
    "            # Load Ridge model directly\n",
    "            model = joblib.load(os.path.join(models_dir, 'ridge_regression_season_model.joblib'))\n",
    "            \n",
    "            # Handle missing values for Ridge\n",
    "            from sklearn.impute import SimpleImputer\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "            X_imputed = pd.DataFrame(\n",
    "                imputer.fit_transform(X_inference),\n",
    "                columns=X_inference.columns,\n",
    "                index=X_inference.index\n",
    "            )\n",
    "            \n",
    "            predictions = model.predict(X_imputed)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            predictions_df = pd.DataFrame(\n",
    "                predictions,\n",
    "                columns=target_cols,\n",
    "                index=X_inference.index\n",
    "            )\n",
    "            \n",
    "        elif model_name == 'xgboost':\n",
    "            # Load XGBoost model directly\n",
    "            model = joblib.load(os.path.join(models_dir, 'xgboost_multioutput_tuned_model.joblib'))\n",
    "            predictions = model.predict(X_inference)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            predictions_df = pd.DataFrame(\n",
    "                predictions,\n",
    "                columns=target_cols,\n",
    "                index=X_inference.index\n",
    "            )\n",
    "            \n",
    "        elif model_name == 'lightgbm':\n",
    "            # Load LightGBM model directly\n",
    "            model = joblib.load(os.path.join(models_dir, 'lightgbm_multioutput_tuned_model.joblib'))\n",
    "            predictions = model.predict(X_inference)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            predictions_df = pd.DataFrame(\n",
    "                predictions,\n",
    "                columns=target_cols,\n",
    "                index=X_inference.index\n",
    "            )\n",
    "            \n",
    "        elif model_name == 'bayesian':\n",
    "            # Load Bayesian model\n",
    "            import arviz as az\n",
    "            trace = az.from_netcdf(os.path.join(models_dir, 'bayesian_multioutput_trace.nc'))\n",
    "            scaler = joblib.load(os.path.join(models_dir, 'bayesian_multioutput_scaler.joblib'))\n",
    "            imputer_X = joblib.load(os.path.join(models_dir, 'bayesian_multioutput_imputer_X.joblib'))\n",
    "            \n",
    "            # Preprocess data\n",
    "            X_processed = pd.DataFrame(\n",
    "                imputer_X.transform(X_inference),\n",
    "                columns=X_inference.columns,\n",
    "                index=X_inference.index\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            X_scaled = scaler.transform(X_processed)\n",
    "            \n",
    "            # Get predictions\n",
    "            beta_samples = trace.posterior['beta'].values\n",
    "            intercept_samples = trace.posterior['intercept'].values\n",
    "            \n",
    "            # Make predictions\n",
    "            pred = np.mean(np.dot(X_scaled, beta_samples) + intercept_samples, axis=(0, 1))\n",
    "            \n",
    "            # Handle shape mismatch - take mean if too many samples\n",
    "            if pred.shape[0] > len(X_inference):\n",
    "                pred_mean = np.mean(pred, axis=0)\n",
    "                pred = np.tile(pred_mean, (len(X_inference), 1))\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            predictions_df = pd.DataFrame(\n",
    "                pred,\n",
    "                columns=target_cols,\n",
    "                index=X_inference.index\n",
    "            )\n",
    "            \n",
    "        elif model_name == 'lstm':\n",
    "            # Load LSTM model using the saved prediction function\n",
    "            import torch\n",
    "            \n",
    "            # Load the saved prediction function\n",
    "            predict_with_lstm_model = joblib.load(os.path.join(models_dir, 'lstm_prediction_function.joblib'))\n",
    "            \n",
    "            # Load model components\n",
    "            model_info = joblib.load(os.path.join(models_dir, 'lstm_model_info.joblib'))\n",
    "            scaler_X = joblib.load(os.path.join(models_dir, 'lstm_scaler_X.joblib'))\n",
    "            scaler_y = joblib.load(os.path.join(models_dir, 'lstm_scaler_y.joblib'))\n",
    "            imputer_X = joblib.load(os.path.join(models_dir, 'lstm_imputer_X.joblib'))\n",
    "            imputer_y = joblib.load(os.path.join(models_dir, 'lstm_imputer_y.joblib'))\n",
    "            \n",
    "            # Load the actual trained model\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            # Define LSTM model class (same as training)\n",
    "            class LSTMModel(torch.nn.Module):\n",
    "                def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
    "                    super(LSTMModel, self).__init__()\n",
    "                    self.hidden_size = hidden_size\n",
    "                    self.num_layers = num_layers\n",
    "                    self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                                             batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "                    self.fc1 = torch.nn.Linear(hidden_size, hidden_size // 2)\n",
    "                    self.dropout = torch.nn.Dropout(dropout)\n",
    "                    self.fc2 = torch.nn.Linear(hidden_size // 2, output_size)\n",
    "                    self.relu = torch.nn.ReLU()\n",
    "                \n",
    "                def forward(self, x):\n",
    "                    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "                    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "                    lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "                    lstm_out = lstm_out[:, -1, :]\n",
    "                    out = self.relu(self.fc1(lstm_out))\n",
    "                    out = self.dropout(out)\n",
    "                    out = self.fc2(out)\n",
    "                    return out\n",
    "            \n",
    "            # Create and load the model\n",
    "            model = LSTMModel(\n",
    "                input_size=model_info['input_size'],\n",
    "                hidden_size=model_info['hidden_size'],\n",
    "                num_layers=model_info['num_layers'],\n",
    "                output_size=model_info['output_size'],\n",
    "                dropout=model_info['dropout']\n",
    "            )\n",
    "            \n",
    "            model.load_state_dict(torch.load(os.path.join(models_dir, 'lstm_best_model.pth'), map_location=device))\n",
    "            model = model.to(device)\n",
    "            \n",
    "            # Use the saved prediction function\n",
    "            predictions_df = predict_with_lstm_model(\n",
    "                X_inference, model, scaler_X, scaler_y, imputer_X, imputer_y,\n",
    "                feature_cols, target_cols, model_info['sequence_length']\n",
    "            )\n",
    "        \n",
    "        elif model_name == 'transformer':\n",
    "            # Load Transformer model\n",
    "            import torch\n",
    "            \n",
    "            # Load model components\n",
    "            scaler = joblib.load(os.path.join(models_dir, 'transformer_scaler.joblib'))\n",
    "            imputer_X = joblib.load(os.path.join(models_dir, 'transformer_imputer_X.joblib'))\n",
    "            \n",
    "            # Preprocess data\n",
    "            X_processed = pd.DataFrame(\n",
    "                imputer_X.transform(X_inference),\n",
    "                columns=X_inference.columns,\n",
    "                index=X_inference.index\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            X_scaled = scaler.transform(X_processed)\n",
    "            \n",
    "            # Load and use transformer prediction function\n",
    "            try:\n",
    "                predict_with_transformer_model = joblib.load(os.path.join(models_dir, 'transformer_prediction_function.joblib'))\n",
    "                predictions = predict_with_transformer_model(X_scaled, models_dir, sequence_length=10)\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                predictions_df = pd.DataFrame(\n",
    "                    predictions,\n",
    "                    columns=target_cols,\n",
    "                    index=X_inference.index\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Transformer prediction function failed: {e}\")\n",
    "                # Fallback: create dummy predictions\n",
    "                predictions_df = pd.DataFrame(\n",
    "                    np.zeros((len(X_inference), len(target_cols))),\n",
    "                    columns=target_cols,\n",
    "                    index=X_inference.index\n",
    "                )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "        \n",
    "        return predictions_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name} model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and running all individual models...\n",
      "\n",
      "Running RIDGE model...\n",
      "  RIDGE predictions shape: (422, 21)\n",
      "  Sample predictions:\n",
      "   next_Points  next_FTM  next_FTA  next_FGM   next_FGA   next_TO  next_STL  \\\n",
      "0    25.344830  4.655561  5.839144  9.355871  18.144210  1.270610  0.687263   \n",
      "1    10.113258  0.968518  1.161410  3.807077   8.584739  1.272870  0.118369   \n",
      "2     8.707215  1.168798  1.410836  2.942211   7.210588  1.065596  0.261160   \n",
      "\n",
      "   next_BLK   next_PF  next_USAGE_RATE  ...  next_DREB  next_AST  next_REB  \\\n",
      "0  3.301547  1.773465        60.665309  ...   6.612565  7.763742  7.776291   \n",
      "1  1.574110  1.693445        36.941078  ...   3.145372  6.380347  3.532516   \n",
      "2  1.438889  2.134729        31.657852  ...   2.560087  4.298455  3.054039   \n",
      "\n",
      "   next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%   next_FG%  \\\n",
      "0     36.414858  1.977527  5.203516  34.387224  80.338979  54.053778   \n",
      "1     27.473128  1.530586  3.954138  34.846396  79.513747  42.803483   \n",
      "2     28.296150  1.653995  4.333347  34.125244  80.352015  40.841879   \n",
      "\n",
      "   next_GAME_EFFICIENCY  \n",
      "0             53.029000  \n",
      "1             26.034886  \n",
      "2             21.154245  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "\n",
      "Running XGBOOST model...\n",
      "  XGBOOST predictions shape: (422, 21)\n",
      "  Sample predictions:\n",
      "   next_Points  next_FTM  next_FTA  next_FGM   next_FGA   next_TO  next_STL  \\\n",
      "0    26.751406  4.529183  5.749719  9.579248  18.767910  1.219375  0.659560   \n",
      "1    10.791398  1.025853  1.126171  3.989152   8.906222  1.120381  0.175157   \n",
      "2     7.563018  0.911904  1.049513  2.694652   6.136894  0.975384  0.338128   \n",
      "\n",
      "   next_BLK   next_PF  next_USAGE_RATE  ...  next_DREB  next_AST  next_REB  \\\n",
      "0  3.249100  1.501884        62.652950  ...   6.087924  8.011604  7.119710   \n",
      "1  1.483387  1.835089        36.553719  ...   3.250488  6.831813  3.717677   \n",
      "2  1.187925  2.225302        28.814554  ...   2.649901  4.008724  3.064112   \n",
      "\n",
      "   next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%   next_FG%  \\\n",
      "0     35.541100  2.353080  5.885365  35.357246  79.180542  51.853249   \n",
      "1     26.799526  1.394689  3.685348  34.985455  80.481613  42.443459   \n",
      "2     26.618795  1.602346  4.246966  36.282852  79.236710  42.118607   \n",
      "\n",
      "   next_GAME_EFFICIENCY  \n",
      "0             52.639984  \n",
      "1             27.009951  \n",
      "2             21.086275  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "\n",
      "Running LIGHTGBM model...\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "  LIGHTGBM predictions shape: (422, 21)\n",
      "  Sample predictions:\n",
      "   next_Points  next_FTM  next_FTA  next_FGM   next_FGA   next_TO  next_STL  \\\n",
      "0    25.046067  4.553007  5.544917  9.508955  18.339749  1.240319  0.673341   \n",
      "1    10.710691  1.164386  1.404756  3.629628   8.628886  1.104934  0.185314   \n",
      "2     7.978705  1.087625  1.382815  2.978889   6.872906  0.908118  0.340730   \n",
      "\n",
      "   next_BLK   next_PF  next_USAGE_RATE  ...  next_DREB  next_AST  next_REB  \\\n",
      "0  3.236255  1.493060        63.252406  ...   5.968052  7.636030  7.125201   \n",
      "1  1.416139  1.888293        38.490291  ...   3.178625  5.837396  3.675001   \n",
      "2  1.330624  2.233565        31.584638  ...   2.730998  3.584973  3.290944   \n",
      "\n",
      "   next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%   next_FG%  \\\n",
      "0     34.850199  2.275446  5.790111  34.994334  77.220659  51.031296   \n",
      "1     25.604929  1.432718  3.880418  34.546070  80.933743  42.588212   \n",
      "2     26.820764  1.637835  4.369792  36.443019  78.734940  42.516588   \n",
      "\n",
      "   next_GAME_EFFICIENCY  \n",
      "0             50.804639  \n",
      "1             25.388362  \n",
      "2             21.625744  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "\n",
      "Running BAYESIAN model...\n",
      "  BAYESIAN predictions shape: (422, 21)\n",
      "  Sample predictions:\n",
      "   next_Points  next_FTM  next_FTA  next_FGM  next_FGA  next_TO  next_STL  \\\n",
      "0    10.971788  1.647373  2.070452  4.031395  8.535191  0.71669    0.4663   \n",
      "1    10.971788  1.647373  2.070452  4.031395  8.535191  0.71669    0.4663   \n",
      "2    10.971788  1.647373  2.070452  4.031395  8.535191  0.71669    0.4663   \n",
      "\n",
      "   next_BLK   next_PF  next_USAGE_RATE  ...  next_DREB  next_AST  next_REB  \\\n",
      "0  1.208214  1.760904        42.401774  ...   3.040149  2.549289  3.992077   \n",
      "1  1.208214  1.760904        42.401774  ...   3.040149  2.549289  3.992077   \n",
      "2  1.208214  1.760904        42.401774  ...   3.040149  2.549289  3.992077   \n",
      "\n",
      "   next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%   next_FG%  \\\n",
      "0     22.768759  1.264111  3.450832  32.351911  76.667633  46.129529   \n",
      "1     22.768759  1.264111  3.450832  32.351911  76.667633  46.129529   \n",
      "2     22.768759  1.264111  3.450832  32.351911  76.667633  46.129529   \n",
      "\n",
      "   next_GAME_EFFICIENCY  \n",
      "0             22.218008  \n",
      "1             22.218008  \n",
      "2             22.218008  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "\n",
      "Running LSTM model...\n",
      "Error with lstm model: Can't get attribute 'predict_with_lstm_model' on <module '__main__'>\n",
      "  LSTM failed to run\n",
      "\n",
      "Running TRANSFORMER model...\n",
      "Transformer prediction function failed: Can't get attribute 'predict_with_transformer_model' on <module '__main__'>\n",
      "  TRANSFORMER predictions shape: (422, 21)\n",
      "  Sample predictions:\n",
      "   next_Points  next_FTM  next_FTA  next_FGM  next_FGA  next_TO  next_STL  \\\n",
      "0          0.0       0.0       0.0       0.0       0.0      0.0       0.0   \n",
      "1          0.0       0.0       0.0       0.0       0.0      0.0       0.0   \n",
      "2          0.0       0.0       0.0       0.0       0.0      0.0       0.0   \n",
      "\n",
      "   next_BLK  next_PF  next_USAGE_RATE  ...  next_DREB  next_AST  next_REB  \\\n",
      "0       0.0      0.0              0.0  ...        0.0       0.0       0.0   \n",
      "1       0.0      0.0              0.0  ...        0.0       0.0       0.0   \n",
      "2       0.0      0.0              0.0  ...        0.0       0.0       0.0   \n",
      "\n",
      "   next_Minutes  next_3PM  next_3PA  next_3P%  next_FT%  next_FG%  \\\n",
      "0           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   next_GAME_EFFICIENCY  \n",
      "0                   0.0  \n",
      "1                   0.0  \n",
      "2                   0.0  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "\n",
      "Successfully ran 5 individual models\n"
     ]
    }
   ],
   "source": [
    "# Load and run all individual models\n",
    "print(\"Loading and running all individual models...\")\n",
    "\n",
    "models = ['ridge', 'xgboost', 'lightgbm', 'bayesian', 'lstm', 'transformer']\n",
    "individual_predictions = {}\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"\\nRunning {model_name.upper()} model...\")\n",
    "    pred_df = load_model_predictions(model_name, X_inference, models_dir)\n",
    "    \n",
    "    if pred_df is not None:\n",
    "        individual_predictions[model_name] = pred_df\n",
    "        print(f\"  {model_name.upper()} predictions shape: {pred_df.shape}\")\n",
    "        print(f\"  Sample predictions:\")\n",
    "        print(pred_df.head(3))\n",
    "    else:\n",
    "        print(f\"  {model_name.upper()} failed to run\")\n",
    "\n",
    "print(f\"\\nSuccessfully ran {len(individual_predictions)} individual models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Ensemble Predictions\n",
    "\n",
    "We'll create ensemble predictions using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating ensemble predictions...\n",
      "  Simple average shape: (422, 21)\n",
      "  Weighted average shape: (422, 21)\n",
      "  Stacking ensemble failed: X has 105 features, but Ridge is expecting 84 features as input.\n",
      "Created 2 ensemble methods\n",
      "\n",
      "Total prediction methods: 7\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble predictions\n",
    "print(\"\\nCreating ensemble predictions...\")\n",
    "\n",
    "ensemble_predictions = {}\n",
    "\n",
    "if len(individual_predictions) > 1:\n",
    "    # Get all prediction arrays\n",
    "    pred_arrays = [individual_predictions[model].values for model in individual_predictions.keys()]\n",
    "    \n",
    "    # Simple averaging (excluding transformer)\n",
    "    simple_models = [m for m in individual_predictions.keys() if m != 'transformer']\n",
    "    if len(simple_models) > 1:\n",
    "        simple_pred_arrays = [individual_predictions[model].values for model in simple_models]\n",
    "        simple_avg_pred = np.mean(simple_pred_arrays, axis=0)\n",
    "        \n",
    "        simple_avg_df = pd.DataFrame(\n",
    "            simple_avg_pred,\n",
    "            columns=target_cols,\n",
    "            index=X_inference.index\n",
    "        )\n",
    "        \n",
    "        ensemble_predictions['ensemble_simple'] = simple_avg_df\n",
    "        print(f\"  Simple average shape: {simple_avg_df.shape}\")\n",
    "    \n",
    "    # Weighted averaging (excluding transformer)\n",
    "    if len(simple_models) > 1:\n",
    "        weights = np.ones(len(simple_models)) / len(simple_models)\n",
    "        weighted_avg_pred = np.sum([weights[i] * simple_pred_arrays[i] for i in range(len(simple_pred_arrays))], axis=0)\n",
    "        \n",
    "        weighted_avg_df = pd.DataFrame(\n",
    "            weighted_avg_pred,\n",
    "            columns=target_cols,\n",
    "            index=X_inference.index\n",
    "        )\n",
    "        \n",
    "        ensemble_predictions['ensemble_weighted'] = weighted_avg_df\n",
    "        print(f\"  Weighted average shape: {weighted_avg_df.shape}\")\n",
    "    \n",
    "    # Stacking ensemble (including transformer)\n",
    "    try:\n",
    "        # Load ensemble results for stacking\n",
    "        ensemble_results = joblib.load(os.path.join(models_dir, 'ensemble_results.joblib'))\n",
    "        \n",
    "        # Use the stacking meta-learner\n",
    "        meta_learner = ensemble_results['stacking']['meta_learner']\n",
    "        \n",
    "        # Prepare meta-features from all models\n",
    "        all_pred_arrays = [individual_predictions[model].values for model in individual_predictions.keys()]\n",
    "        meta_features = np.stack(all_pred_arrays, axis=0).transpose(1, 0, 2).reshape(len(X_inference), -1)\n",
    "        \n",
    "        # Make stacking predictions\n",
    "        stacking_pred_flat = meta_learner.predict(meta_features)\n",
    "        stacking_pred = stacking_pred_flat.reshape(len(X_inference), len(target_cols))\n",
    "        \n",
    "        stacking_df = pd.DataFrame(\n",
    "            stacking_pred,\n",
    "            columns=target_cols,\n",
    "            index=X_inference.index\n",
    "        )\n",
    "        \n",
    "        ensemble_predictions['ensemble_stacking'] = stacking_df\n",
    "        print(f\"  Stacking ensemble shape: {stacking_df.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Stacking ensemble failed: {e}\")\n",
    "    \n",
    "    print(f\"Created {len(ensemble_predictions)} ensemble methods\")\n",
    "else:\n",
    "    print(\"Not enough models for ensemble\")\n",
    "\n",
    "# Combine all predictions\n",
    "all_predictions = {**individual_predictions, **ensemble_predictions}\n",
    "print(f\"\\nTotal prediction methods: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Individual Model Predictions as CSV Files with Player Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving predictions as individual CSV files with player mapping...\n",
      "  Saved ridge predictions to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/ridge_predictions_20250707_124240.csv\n",
      "  Shape: (422, 24)\n",
      "  Sample data:\n",
      "   PERSON_ID SEASON_ID INPUT_SEASON_ID  next_Points  next_FTM  next_FTA  \\\n",
      "0     2544.0   2025-26         2023-24    25.344830  4.655561  5.839144   \n",
      "1   101108.0   2025-26         2023-24    10.113258  0.968518  1.161410   \n",
      "2   200768.0   2025-26         2023-24     8.707215  1.168798  1.410836   \n",
      "\n",
      "   next_FGM   next_FGA   next_TO  next_STL  ...  next_DREB  next_AST  \\\n",
      "0  9.355871  18.144210  1.270610  0.687263  ...   6.612565  7.763742   \n",
      "1  3.807077   8.584739  1.272870  0.118369  ...   3.145372  6.380347   \n",
      "2  2.942211   7.210588  1.065596  0.261160  ...   2.560087  4.298455   \n",
      "\n",
      "   next_REB  next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%  \\\n",
      "0  7.776291     36.414858  1.977527  5.203516  34.387224  80.338979   \n",
      "1  3.532516     27.473128  1.530586  3.954138  34.846396  79.513747   \n",
      "2  3.054039     28.296150  1.653995  4.333347  34.125244  80.352015   \n",
      "\n",
      "    next_FG%  next_GAME_EFFICIENCY  \n",
      "0  54.053778             53.029000  \n",
      "1  42.803483             26.034886  \n",
      "2  40.841879             21.154245  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "  Saved xgboost predictions to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/xgboost_predictions_20250707_124240.csv\n",
      "  Shape: (422, 24)\n",
      "  Sample data:\n",
      "   PERSON_ID SEASON_ID INPUT_SEASON_ID  next_Points  next_FTM  next_FTA  \\\n",
      "0     2544.0   2025-26         2023-24    26.751406  4.529183  5.749719   \n",
      "1   101108.0   2025-26         2023-24    10.791398  1.025853  1.126171   \n",
      "2   200768.0   2025-26         2023-24     7.563018  0.911904  1.049513   \n",
      "\n",
      "   next_FGM   next_FGA   next_TO  next_STL  ...  next_DREB  next_AST  \\\n",
      "0  9.579248  18.767910  1.219375  0.659560  ...   6.087924  8.011604   \n",
      "1  3.989152   8.906222  1.120381  0.175157  ...   3.250488  6.831813   \n",
      "2  2.694652   6.136894  0.975384  0.338128  ...   2.649901  4.008724   \n",
      "\n",
      "   next_REB  next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%  \\\n",
      "0  7.119710     35.541100  2.353080  5.885365  35.357246  79.180542   \n",
      "1  3.717677     26.799526  1.394689  3.685348  34.985455  80.481613   \n",
      "2  3.064112     26.618795  1.602346  4.246966  36.282852  79.236710   \n",
      "\n",
      "    next_FG%  next_GAME_EFFICIENCY  \n",
      "0  51.853249             52.639984  \n",
      "1  42.443459             27.009951  \n",
      "2  42.118607             21.086275  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "  Saved lightgbm predictions to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/lightgbm_predictions_20250707_124240.csv\n",
      "  Shape: (422, 24)\n",
      "  Sample data:\n",
      "   PERSON_ID SEASON_ID INPUT_SEASON_ID  next_Points  next_FTM  next_FTA  \\\n",
      "0     2544.0   2025-26         2023-24    25.046067  4.553007  5.544917   \n",
      "1   101108.0   2025-26         2023-24    10.710691  1.164386  1.404756   \n",
      "2   200768.0   2025-26         2023-24     7.978705  1.087625  1.382815   \n",
      "\n",
      "   next_FGM   next_FGA   next_TO  next_STL  ...  next_DREB  next_AST  \\\n",
      "0  9.508955  18.339749  1.240319  0.673341  ...   5.968052  7.636030   \n",
      "1  3.629628   8.628886  1.104934  0.185314  ...   3.178625  5.837396   \n",
      "2  2.978889   6.872906  0.908118  0.340730  ...   2.730998  3.584973   \n",
      "\n",
      "   next_REB  next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%  \\\n",
      "0  7.125201     34.850199  2.275446  5.790111  34.994334  77.220659   \n",
      "1  3.675001     25.604929  1.432718  3.880418  34.546070  80.933743   \n",
      "2  3.290944     26.820764  1.637835  4.369792  36.443019  78.734940   \n",
      "\n",
      "    next_FG%  next_GAME_EFFICIENCY  \n",
      "0  51.031296             50.804639  \n",
      "1  42.588212             25.388362  \n",
      "2  42.516588             21.625744  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "  Saved bayesian predictions to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/bayesian_predictions_20250707_124240.csv\n",
      "  Shape: (422, 24)\n",
      "  Sample data:\n",
      "   PERSON_ID SEASON_ID INPUT_SEASON_ID  next_Points  next_FTM  next_FTA  \\\n",
      "0     2544.0   2025-26         2023-24    10.971788  1.647373  2.070452   \n",
      "1   101108.0   2025-26         2023-24    10.971788  1.647373  2.070452   \n",
      "2   200768.0   2025-26         2023-24    10.971788  1.647373  2.070452   \n",
      "\n",
      "   next_FGM  next_FGA  next_TO  next_STL  ...  next_DREB  next_AST  next_REB  \\\n",
      "0  4.031395  8.535191  0.71669    0.4663  ...   3.040149  2.549289  3.992077   \n",
      "1  4.031395  8.535191  0.71669    0.4663  ...   3.040149  2.549289  3.992077   \n",
      "2  4.031395  8.535191  0.71669    0.4663  ...   3.040149  2.549289  3.992077   \n",
      "\n",
      "   next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%   next_FG%  \\\n",
      "0     22.768759  1.264111  3.450832  32.351911  76.667633  46.129529   \n",
      "1     22.768759  1.264111  3.450832  32.351911  76.667633  46.129529   \n",
      "2     22.768759  1.264111  3.450832  32.351911  76.667633  46.129529   \n",
      "\n",
      "   next_GAME_EFFICIENCY  \n",
      "0             22.218008  \n",
      "1             22.218008  \n",
      "2             22.218008  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "  Saved transformer predictions to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/transformer_predictions_20250707_124240.csv\n",
      "  Shape: (422, 24)\n",
      "  Sample data:\n",
      "   PERSON_ID SEASON_ID INPUT_SEASON_ID  next_Points  next_FTM  next_FTA  \\\n",
      "0     2544.0   2025-26         2023-24          0.0       0.0       0.0   \n",
      "1   101108.0   2025-26         2023-24          0.0       0.0       0.0   \n",
      "2   200768.0   2025-26         2023-24          0.0       0.0       0.0   \n",
      "\n",
      "   next_FGM  next_FGA  next_TO  next_STL  ...  next_DREB  next_AST  next_REB  \\\n",
      "0       0.0       0.0      0.0       0.0  ...        0.0       0.0       0.0   \n",
      "1       0.0       0.0      0.0       0.0  ...        0.0       0.0       0.0   \n",
      "2       0.0       0.0      0.0       0.0  ...        0.0       0.0       0.0   \n",
      "\n",
      "   next_Minutes  next_3PM  next_3PA  next_3P%  next_FT%  next_FG%  \\\n",
      "0           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "1           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "2           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "   next_GAME_EFFICIENCY  \n",
      "0                   0.0  \n",
      "1                   0.0  \n",
      "2                   0.0  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "  Saved ensemble_simple predictions to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/ensemble_simple_predictions_20250707_124240.csv\n",
      "  Shape: (422, 24)\n",
      "  Sample data:\n",
      "   PERSON_ID SEASON_ID INPUT_SEASON_ID  next_Points  next_FTM  next_FTA  \\\n",
      "0     2544.0   2025-26         2023-24    22.028523  3.846281  4.801058   \n",
      "1   101108.0   2025-26         2023-24    10.646784  1.201532  1.440697   \n",
      "2   200768.0   2025-26         2023-24     8.805181  1.203925  1.478404   \n",
      "\n",
      "   next_FGM   next_FGA   next_TO  next_STL  ...  next_DREB  next_AST  \\\n",
      "0  8.118867  15.946765  1.111749  0.621616  ...   5.427173  6.490166   \n",
      "1  3.864313   8.663760  1.053718  0.236285  ...   3.153659  5.399711   \n",
      "2  3.161787   7.188895  0.916447  0.351579  ...   2.745284  3.610360   \n",
      "\n",
      "   next_REB  next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%  \\\n",
      "0  6.503320     32.393729  1.967541  5.082456  34.272679  78.351953   \n",
      "1  3.729317     25.661585  1.405526  3.742684  34.182458  79.399184   \n",
      "2  3.350293     26.126117  1.539572  4.100234  34.800756  78.747824   \n",
      "\n",
      "    next_FG%  next_GAME_EFFICIENCY  \n",
      "0  50.766963             44.672908  \n",
      "1  43.491171             25.162802  \n",
      "2  42.901651             21.521068  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "  Saved ensemble_weighted predictions to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/ensemble_weighted_predictions_20250707_124240.csv\n",
      "  Shape: (422, 24)\n",
      "  Sample data:\n",
      "   PERSON_ID SEASON_ID INPUT_SEASON_ID  next_Points  next_FTM  next_FTA  \\\n",
      "0     2544.0   2025-26         2023-24    22.028523  3.846281  4.801058   \n",
      "1   101108.0   2025-26         2023-24    10.646784  1.201532  1.440697   \n",
      "2   200768.0   2025-26         2023-24     8.805181  1.203925  1.478404   \n",
      "\n",
      "   next_FGM   next_FGA   next_TO  next_STL  ...  next_DREB  next_AST  \\\n",
      "0  8.118867  15.946765  1.111749  0.621616  ...   5.427173  6.490166   \n",
      "1  3.864313   8.663760  1.053718  0.236285  ...   3.153659  5.399711   \n",
      "2  3.161787   7.188895  0.916447  0.351579  ...   2.745284  3.610360   \n",
      "\n",
      "   next_REB  next_Minutes  next_3PM  next_3PA   next_3P%   next_FT%  \\\n",
      "0  6.503320     32.393729  1.967541  5.082456  34.272679  78.351953   \n",
      "1  3.729317     25.661585  1.405526  3.742684  34.182458  79.399184   \n",
      "2  3.350293     26.126117  1.539572  4.100234  34.800756  78.747824   \n",
      "\n",
      "    next_FG%  next_GAME_EFFICIENCY  \n",
      "0  50.766963             44.672908  \n",
      "1  43.491171             25.162802  \n",
      "2  42.901651             21.521068  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "\n",
      "All predictions saved successfully as CSV files with player mapping!\n"
     ]
    }
   ],
   "source": [
    "# Save predictions as individual CSV files with player mapping\n",
    "print(\"\\nSaving predictions as individual CSV files with player mapping...\")\n",
    "\n",
    "# Create timestamp for file naming\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save individual model predictions with player mapping\n",
    "for model_name, pred_df in individual_predictions.items():\n",
    "    # Add player information\n",
    "    pred_df_with_players = pred_df.copy()\n",
    "    pred_df_with_players['PERSON_ID'] = inference_data['PERSON_ID']\n",
    "    pred_df_with_players['SEASON_ID'] = '2025-26'  # Predictions for next season\n",
    "    pred_df_with_players['INPUT_SEASON_ID'] = inference_data['SEASON_ID']  # Season used for prediction\n",
    "    \n",
    "    # Reorder columns to put player info first\n",
    "    player_cols = ['PERSON_ID', 'SEASON_ID', 'INPUT_SEASON_ID']\n",
    "    other_cols = [col for col in pred_df_with_players.columns if col not in player_cols]\n",
    "    pred_df_with_players = pred_df_with_players[player_cols + other_cols]\n",
    "    \n",
    "    filename = f\"{model_name}_predictions_{timestamp}.csv\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    pred_df_with_players.to_csv(filepath, index=False)\n",
    "    print(f\"  Saved {model_name} predictions to: {filepath}\")\n",
    "    print(f\"  Shape: {pred_df_with_players.shape}\")\n",
    "    print(f\"  Sample data:\")\n",
    "    print(pred_df_with_players.head(3))\n",
    "\n",
    "# Save ensemble predictions with player mapping\n",
    "for ensemble_name, pred_df in ensemble_predictions.items():\n",
    "    # Add player information\n",
    "    pred_df_with_players = pred_df.copy()\n",
    "    pred_df_with_players['PERSON_ID'] = inference_data['PERSON_ID']\n",
    "    pred_df_with_players['SEASON_ID'] = '2025-26'  # Predictions for next season\n",
    "    pred_df_with_players['INPUT_SEASON_ID'] = inference_data['SEASON_ID']  # Season used for prediction\n",
    "    \n",
    "    # Reorder columns to put player info first\n",
    "    player_cols = ['PERSON_ID', 'SEASON_ID', 'INPUT_SEASON_ID']\n",
    "    other_cols = [col for col in pred_df_with_players.columns if col not in player_cols]\n",
    "    pred_df_with_players = pred_df_with_players[player_cols + other_cols]\n",
    "    \n",
    "    filename = f\"{ensemble_name}_predictions_{timestamp}.csv\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    pred_df_with_players.to_csv(filepath, index=False)\n",
    "    print(f\"  Saved {ensemble_name} predictions to: {filepath}\")\n",
    "    print(f\"  Shape: {pred_df_with_players.shape}\")\n",
    "    print(f\"  Sample data:\")\n",
    "    print(pred_df_with_players.head(3))\n",
    "\n",
    "print(\"\\nAll predictions saved successfully as CSV files with player mapping!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating summary report...\n",
      "  Saved inference report to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output/inference_report_20250707_124240.joblib\n",
      "\n",
      "============================================================\n",
      "INFERENCE SUMMARY REPORT\n",
      "============================================================\n",
      "Timestamp: 20250707_124240\n",
      "Input data shape: (422, 58)\n",
      "Feature columns: 56\n",
      "Target columns: 21\n",
      "Individual models: 5\n",
      "Ensemble methods: 2\n",
      "Total prediction methods: 7\n",
      "Prediction season: 2025-26\n",
      "Input season: 2024-25\n",
      "\n",
      "Individual Models:\n",
      "  - RIDGE\n",
      "  - XGBOOST\n",
      "  - LIGHTGBM\n",
      "  - BAYESIAN\n",
      "  - TRANSFORMER\n",
      "\n",
      "Ensemble Methods:\n",
      "  - ENSEMBLE_SIMPLE\n",
      "  - ENSEMBLE_WEIGHTED\n",
      "\n",
      "Output files saved to: /Users/jeevanparmar/Uni/MSE 436/Project-Mono-Repo/backend/Output\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create summary report\n",
    "print(\"\\nCreating summary report...\")\n",
    "\n",
    "report = {\n",
    "    'timestamp': timestamp,\n",
    "    'input_data_shape': inference_data.shape,\n",
    "    'feature_columns': len(feature_cols),\n",
    "    'target_columns': len(target_cols),\n",
    "    'models_used': list(all_predictions.keys()),\n",
    "    'individual_models': list(individual_predictions.keys()),\n",
    "    'ensemble_methods': list(ensemble_predictions.keys()),\n",
    "    'predictions_summary': {},\n",
    "    'prediction_season': '2025-26',\n",
    "    'input_season': '2024-25'\n",
    "}\n",
    "\n",
    "# Add summary statistics for each model\n",
    "for model_name, pred_df in all_predictions.items():\n",
    "    report['predictions_summary'][model_name] = {\n",
    "        'shape': pred_df.shape,\n",
    "        'mean_values': pred_df.mean().to_dict(),\n",
    "        'std_values': pred_df.std().to_dict(),\n",
    "        'min_values': pred_df.min().to_dict(),\n",
    "        'max_values': pred_df.max().to_dict()\n",
    "    }\n",
    "\n",
    "# Save report\n",
    "report_filename = f\"inference_report_{timestamp}.joblib\"\n",
    "report_filepath = os.path.join(output_dir, report_filename)\n",
    "joblib.dump(report, report_filepath)\n",
    "print(f\"  Saved inference report to: {report_filepath}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INFERENCE SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Timestamp: {timestamp}\")\n",
    "print(f\"Input data shape: {inference_data.shape}\")\n",
    "print(f\"Feature columns: {len(feature_cols)}\")\n",
    "print(f\"Target columns: {len(target_cols)}\")\n",
    "print(f\"Individual models: {len(individual_predictions)}\")\n",
    "print(f\"Ensemble methods: {len(ensemble_predictions)}\")\n",
    "print(f\"Total prediction methods: {len(all_predictions)}\")\n",
    "print(f\"Prediction season: 2025-26\")\n",
    "print(f\"Input season: 2024-25\")\n",
    "print(f\"\\nIndividual Models:\")\n",
    "for model_name in individual_predictions.keys():\n",
    "    print(f\"  - {model_name.upper()}\")\n",
    "print(f\"\\nEnsemble Methods:\")\n",
    "for ensemble_name in ensemble_predictions.keys():\n",
    "    print(f\"  - {ensemble_name.upper()}\")\n",
    "print(f\"\\nOutput files saved to: {output_dir}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Summary\n",
    "\n",
    "The inference process has been completed successfully. Here's what was accomplished:\n",
    "\n",
    "### Models Used:\n",
    "- **Ridge Regression** (using saved model)\n",
    "- **XGBoost** (using saved model)\n",
    "- **LightGBM** (using saved model)\n",
    "- **Bayesian Multi-Output Regression** (using saved model)\n",
    "- **LSTM** (using saved .pth file)\n",
    "- **Transformer** (using saved .pth file)\n",
    "- **Ensemble Methods** (Simple averaging, Weighted averaging, Stacking)\n",
    "\n",
    "### Key Features:\n",
    "- **Multi-model predictions**: Each model provides its own predictions\n",
    "- **Ensemble combinations**: Simple, weighted, and stacking ensemble methods\n",
    "- **Individual CSV outputs**: Each model's predictions saved as separate CSV files\n",
    "- **Player mapping**: All predictions include PERSON_ID for player identification\n",
    "- **Season tracking**: Clear indication of input season (2024-25) and prediction season (2025-26)\n",
    "- **Frontend ready**: CSV files can be directly used in the frontend\n",
    "- **Robust error handling**: Graceful handling of missing models\n",
    "\n",
    "### Output Files Created:\n",
    "- `ridge_predictions_[timestamp].csv`\n",
    "- `xgboost_predictions_[timestamp].csv`\n",
    "- `lightgbm_predictions_[timestamp].csv`\n",
    "- `bayesian_predictions_[timestamp].csv`\n",
    "- `lstm_predictions_[timestamp].csv`\n",
    "- `transformer_predictions_[timestamp].csv`\n",
    "- `ensemble_simple_predictions_[timestamp].csv`\n",
    "- `ensemble_weighted_predictions_[timestamp].csv`\n",
    "- `ensemble_stacking_predictions_[timestamp].csv` (if available)\n",
    "- `inference_report_[timestamp].joblib`\n",
    "\n",
    "### CSV File Structure:\n",
    "Each CSV file contains:\n",
    "- `PERSON_ID`: Player identification number\n",
    "- `SEASON_ID`: '2025-26' (prediction season)\n",
    "- `INPUT_SEASON_ID`: '2024-25' (season used for prediction)\n",
    "- All 21 predicted statistics (next_Points, next_FTM, etc.)\n",
    "\n",
    "### Usage:\n",
    "These CSV files can be directly loaded into the frontend for visualization and comparison of different model predictions for the 2025-26 NBA season."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
